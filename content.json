{"pages":[{"title":"","text":"urlretrieve(Image_URL,’\\image,png’) r = request.get(Image_URL) with open(‘image.png’, ‘wb’) as f: ​ f.write(r)","link":"/draft/spider下载文件.html"},{"title":"","text":"tensorflow基本概念 使用图(graph)来表示计算任务。 在被称之为会话(Session)的上下文(context)中执行图。 使用tensor表示数据 通过变量(Variable)维护状态 使用feed和fetch可以为任意的操作赋值或者从其中获取数据。 Tensorflow是一个编程系统，使用图表示计算任务，图中的节点称之为op,一个op获得0个或多个Tensorn，执行计算，产生0个或多个Tensor。Tensor看作是一个n维的数组或列表。图必须在会话里被启动。 softmax函数常用于分类，转换为每一类的概率，总概率和为1。 二次代价函数 用梯度下降的话，参数调整不是很合理 交叉熵函数：换一个思路，不改变激活函数，改变代价函数用交叉熵函数。在交叉熵函数中，权值和偏执值调整与激活函数倒数无关。预测值减实际值（误差）大时，梯度越大，调整越快。 如果输出神经元是线性的，二次代价函数是一种合适的选择。输出神经元是S型函数，比较适合用交叉熵。 对数释然代价函数常用来作为softmax回归的代价函数，如果输出层神经元是sigmoid函数，可用交叉熵。深度学习更普遍将softmax作为最后一层，此时代价函数常用对数释然函数。 对数似然函数与softmax组合 和 交叉熵与sigmoid函数组合非常相似。 防止过拟合： 增加数据集 正则化方法 是比较小的权值接近于0，这个神经元不存在，减小网络复杂程度 Dropout 训练过程中每一次迭代过程中使某些神经元不工作，测试时激活所有神经元。 优化器： 标准梯度下降法 随机梯度下降法 批量梯度下降法 SGD Momentum:当前权值改变受到上一次权值改变的影响。 NAG：提前知道方向。 Adagrad：对于比较常见的数据给予比较小的学习率调整参数，罕见的用较大的学习率调参，适合于数据稀疏的数据集。优势在于不需要人为调节学习率，自动调节，缺点是随着迭代次数变多，学习率也会越来越低，最终趋向于0。 RMSprop: RMS是均方根缩写。不会出现学习率越来越低的问题，也会自己调节学习率。 Adadelta: 不需要设置学习率。 Adam: xxxx 从准确率上来讲，随机梯度下降还是比较可靠的。 Adadelta，Adam 模型收敛速度比较快。 在创建新的网络时候，调试网络时候可以使用速度比较快的网络(Adadelta，Adam)，最后发论文出结果的时候把所有优化器都试一遍，看谁结果准确率最高。 卷积神经网络：通过感受野和权值共享减少了神经网络需要训练参数的个数。 RNN（Recurrent Neural Network): 处理语音或是文字时不能单独处理，需要看成一个连续整体，将上一个输出作为下一个输入，帮助决策。 会有梯度消失问题，若换成y=x，但是一直不会减弱，会记录所有结果，重要的不重要的全会记住。我们要有选择性的记忆。 LSTM (Long Short Term Memory) block放在隐藏层的位置，有三个门：输入门，忘记门，输出门 使用已有模型进行训练： 卷积层是为了做特征的提取，这部分对于分类自己的数据是比较适用的。 交替训练：不同任务，不同训练集（英语-&gt;法语/德语) 联合训练：，不同任务，相同训练集。（多个数字的验证码识别） 截图：http://www.cnblogs.com/handy1998/p/9982646.html","link":"/draft/tensorflow.html"},{"title":"","text":"Matplotlib pyplot模块和pylab模块(不太常用) 导入头文件 import matplotlib.pyplot as plt 折线图 plt.plot(x,y) 散点图 plt.plot(x, y, ‘o’) 柱状图 plt.bar(x, y)","link":"/draft/Matplotlib.html"},{"title":"浅谈机器学习与深度学习中的算法原理(一)","text":"当今社会，各行各业无不涉及人工智能和机器学习，掌握其中的基本原理知道如何应用至关重要，同时也是求职者必备技能。本系列博客旨在介绍机器算法和深度学习的基本原理，为进行更深层次的应用打下基础。 本篇文章主要介绍传统学习和机器学习的内容和主要区别。 什么是机器学习？机器学习的定义“A computer program is said to learn from experience E with respect tosome class of tasks T and performance measure P if its performance attasks in T, as measured by P, improves with experience E ” 翻译过来是“一个电脑程序要完成任务(T),如果电脑获取的关于T的经验(E)越多就表现得(P)越好,那么我们就可以说这个程序学习了”。 更直白一点：“经验越多，学习越好”。 比如：根据身高预测体重，根据气压、湿度、风力等预测降雨概率等。 这里需要注意的是，这些机器学习的特征，是人工提前设置好的，在进行这项工作之前，是由人类专家根据自己的以往经验来选取的重要的特征，然后机器通过分析这些特征的历史数据，来找到相应的模式，即不同特征组合下的不同结果。 什么是深度学习？深度学习的定义 “Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of lessabstract ones.” 翻译过来是“深度学习是一种特殊的机器学习，它可以获得高性能也十分灵活。它可以用概念组成的网状层级结构来表示这个世界，每一个概念更简单的概念相连，抽象的概念通过没那么抽象的概念计算。” 以人类判断方形和圆形为例，在判断过程中，我们首先看这个形状有没有四条边，有的话进一步判断是否垂直，是否等长。如果以上条件都能满足，则是一个这正方形。在这个过程中，我们的大脑自动将识别的整个复杂的任务分为了几个简单的小块。 传统机器学习与深度学习有何区别？在识别猫和狗的过程中，若使用传统机器学习的算法，我们需要定义一些特征，告诉机器从哪些方面进行判断，比如，胡须、耳朵、鼻子、嘴巴的模样。首先要确定相应的面部特征，作为机器学习的特征，以便分类判断。 而深度学习的工作流程如下：1. 首先确定出有哪些边和角跟识别出猫狗关系最大; 2.根据上一步找出的很多小元素（边、角等）构建层级网络，找出它们之间的各种组合; 3.在构建层级网络之后，就可以确定哪些组合可以识别出猫和狗。 深度学习方法的优越性就体现在，它能自动找到这个问题所需要的重要特征，而传统机器学习需要手工的给出特征。 以人脸识别为例：可以看到4层，输入的是Raw Data，就是原始数据，这个机器没法理解。于是，深度学习首先尽可能找到与这个头像相关的各种边，这些边就是底层的特征（Low-level features），这就是上面写的第一步；然后下一步，对这些底层特征进行组合，就可以看到有鼻子、眼睛、耳朵等等，它们就是中间层特征（Mid-level features），这就是上面写的第二步；最后，我们队鼻子眼睛耳朵等进行组合，就可以组成各种各样的头像了，也就是高层特征（High-level features）这个时候就可以识别出或者分类出各种人的头像了。 对比机器学习和深度学习，可以发现以下不同点： 数据依赖 随着数据量增加，两者表现有很大区别： 数据集较大时，可以使用深度学习方法；数据集较小，用传统机器学习方法或许更合适。 硬件依赖 深度学习十分依赖于高端的硬件设施，因为计算量巨大。深度学习涉及很多矩阵运算，因此很多深度学习都涉及GPU运算，对比之下，机器学习要求配置较低。 特征工程 在机器学习中，几乎所有特征都业内专家确定，手工对特征进行编码量化。 深度学习中，算法自动从数据中学习特征，大大降低发现特征的成本。 解决问题的方式 传统机器学习算法需要将问题分成几块，一个个解决好之后重新组合起来。 深度学习端到端，一次性解决好。 在物体检测方面，机器学习做法分两步，发现物体（找到物体的位置），识别物体（确定是什么类型的物体）。而在深度学习中，给它一张图，它能直接把物体识别出来，同时标明物体的名字，如yolo算法。 运行时间 深度学习需要花大量时间来训练，ResNet需要两周时间训练。机器学习几秒钟到几个小时就可以训练好。但是机器学习模型一旦训练好，在预测任务上面就会表现很快，如上图视频中实时识别。 可理解性 深度学习就像一个黑盒子，每一层代表一个特征，里面的层多了，它所表示的特征就很难以理解。我们没法对训练出来的模型对于预测任务做一个合理的解释。机器学习则不存在这一问题，在决策树算法中，我们能将每一个规则都能列出来。 参考机器学习和深度学习的科普文：https://www.analyticsvidhya.com/blog/2017/04/comparison-between-deep-learning-machine-learning/ 常见的机器学习算法理解传统机器学习从一些观测（训练）样本出发，试图发现不能通过原理分析获得的规律，实现对未来数据行为或趋势的准确预测。 相关算法包括： K 近邻方法 决策树方法 三层人工神经网络方法 Adaboost算法 贝叶斯方法 逻辑回归 隐马尔科夫方法 支持向量机方法","link":"/draft/浅谈机器学习与深度学习中的算法原理-一.html"},{"title":"浅谈机器学习算法三","text":"","link":"/draft/浅谈机器学习算法三.html"},{"title":"About","text":"目前就读于武汉大学，即将当一名出国狗。 博客用来记录生活和技术，欢迎大家一起交流。 有问题请联系我：shuoc1218@163.com","link":"/about/index.html"},{"title":"","text":"Pytorch入门学习参考: https://pytorch.apachecn.org/#/docs/2 1.pytorch的安装这里推荐使用pip进行pytorch的安装，命令行输入 install pytorch```1234567891011pytorch是一个基于Python的科学计算包，其主要是为了解决两类场景* numpy的替代品* 一个深度学习研究平台，提供最大的灵活性和速度。张量 Tensor这个概念相信大家已经多次接触到了，无论是在tesorflow中还是numpy中的ndarrays。构建张量 torch.Tensor(5,3) #创建5*3矩阵x = torch.rand(5,3) #随机初始化矩阵print(x.size()) #打印矩阵大小1234操作：加法 y = torch.rand(5,3)print(x+y) #第一种写法print(torch.add(x,y)) #第二种写法result = torch.Tensor(5,3)torch.add(x, y, out = result)print(result)y.add_(x) #第三种写法 就地操作 in-place123456任何张量的操作都是以后缀_结尾的。改变大小: `torch.view`Torch Tensor 和 NumPy 数组将会共享它们的实际的内存位置, 改变一个另一个也会跟着改变。 a = torch.ones(5)print(a)b = a.numpy()print(b) a.add_(1)print(a)print(b) # a,b均会改变 a = np.ones(5)b = torch.from_numpy(a) #np转化为numpy1234CUDA Tensors可以用.cuda方法将Tensors在GPU上运行 if torch.cuda.is_available(): x = x.cuda() y = y.cuda() x + y #只要在CUDA可用的情况下可以运行12345678910111213141516171819202122#### 2.Autograd(自动求导)​ Pytorch中所有神经网络的核心是autograd自动求导包。​ `autograd` 包为张量上的所有操作提供了自动求导。它是一个运行时定义的框架，意味着反向传播是根据你的代码运行来定义，并且迭代可以不同。- 变量(Variable)​ autograd.Variable是autograd包的核心类。它包装了张量(Tensor),支持几乎所有的张量上的操作，一旦完成了前向(forward)计算，可以通过.backward()方法来自动计算所有的梯度。- 函数(Function) 对自动求导的实现还有另一个非常重要的类，函数。​ 变量`(Variable)`和函数(`Function)`是相互联系的，并形成一个非循环图来构建一个完整的计算过程，每一个变量有一个`.grad_fn`属性，它指向创建该变量的一个`Function`，用户自己创建的变量除外，它的`grad_fn`为`None`.​ 计算导数的时候，可以在一个变量上调用.backward()。如果一个`Variable`是一个标量(仅有一个元素值)，则不必给该方法指定任何的参数，但是`Variable`有多个值，你需要指定一个跟该变量相同形状的`grad_output`参数。 #包含头文件import torchfrom torch.autograd import Variable #创建变量x = Variable(torch.ones(2,2), requires_grad = True)y = x + 2 #y是通过一个操作创建的，所以有grad_fn,而x是用户创建的，所以它的grad_fn为Nonez = y y 3out = z.mean()print(z, out)1234- 梯度 执行反向传播`out.backward()`,相当于执行`out.backward(torch.Tensor([1,.0]))` out.backward() 12输出`out`对`x`的梯度 $\\frac{d o}{d x}$ print(x.grad) #output Variable containing: 4.5000 4.5000 4.5000 4.5000 [torch.FloatTensor of size 2x2] 1234567891011121314151617181920212223242526272829得到结果全为4.5的矩阵，与实际计算结果相同。$$o = \\frac{1}{4}\\sum_iz_i, z_i = 3(x_i+2)^2, \\frac{\\partial o}{\\partial x_i} = \\frac {3}{2}(x_i+2) = 4.5$$注意这里求导方法，out.backward()和x.grad表示的就是out对x的求导。#### 3.神经网络使用torch.nn包来构建神经网络。`nn`包依赖于`autograd`包来定义模型并求导。一个`nn.Module`包含各个层和一个` forward(input)` 方法，该方法返回`output`。一般的神经网络的典型训练过程如下: 1. 定义神经网络模型,它有一些可学习的参数(或者权重); 2. 在数据集上迭代; 3. 通过神经网络处理输入; 4. 计算损失(输出结果和正确值的差距大小) 5. 将梯度反向传播会网络的参数; 6. 更新网络的参数,主要使用如下简单的更新原则: `weight = weight - learning_rate * gradient`首先定义一个网络 import torch from torch.autograd import Variable import torch.nn import torch.nn.functional as F class Net(nn.Module): def init(self): super(Net, self).init() # 1 input image channel, 6 output channels, 5*5 square convolution # kernel self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) #output: Net ( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear (400 -&gt; 120) (fc2): Linear (120 -&gt; 84) (fc3): Linear (84 -&gt; 10) ) 12只需要定义`forward`函数，`backward`函数(计算梯度)在使用`autograd`时自动创建。可以在`forward`函数中使用`Tensor`的任何操作。`net.parameters()`返回模型需要学习的参数。 params = list(net.parameters()) print(len(params)) for param in params: print(param.size()) #output: 10 torch.Size([6, 1, 5, 5]) torch.Size([6]) torch.Size([16, 6, 5, 5]) torch.Size([16]) torch.Size([120, 400]) torch.Size([120]) torch.Size([84, 120]) torch.Size([84]) torch.Size([10, 84]) torch.Size([10]) 12345678910111213141516171819202122`forward`的输入和输出都是`autograd.Variable`。回顾：- `torch.Tensor`-一个多维数组- `autograd.Variable`-包装一个`Tensor`,记录在其上执行过的操作.除了拥有`Tensor`拥有的API,还有类似`backward()`的API.也保存关于这个向量的梯度.- `nn.Module`-神经网络模块.封装参数,移动到GPU上运行,导出,加载等- `nn.Parameter`-一种变量,当把它赋值给一个`Module`时,被自动的注册为一个参数.- `autograd.Function`-实现一个自动求导操作的前向和反向定义,每个变量操作至少创建一个函数节点,(Every `Variable` operation, creates at least a single `Function` node, that connects to functions that created a `Variable` and *encodes its history*.)计算损失函数一个损失函数接受一对`(output, target)`作为输入，其中output为网络的输出，target为实际值，计算一个值来估计网络的输出和目标值相差多少。在`nn`包中有几种不同的损失函数，一个简单的损失函数是:`nn.MSELoss`，他计算输入和目标值之间的均方误差。例如 out = net(input) target = Variable(torch.arange(1, 11)) # a dummy target, for example criterion = nn.MSELoss() loss = criterion(out, target) print(loss) #output: Variable containing: 38.1365 [torch.FloatTensor of size 1] 12反向跟踪`loss`,使用它的`.grad_fn`属性，会看到下面这张计算图: input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear -&gt; MSELoss -&gt; loss 123456789101112131415161718当调用`loss.backward()`，整个图关于损失函数被求导，图中所有变量将拥有`.grad`变量来累计梯度。反向传播为了反向传播误差，我们需要调用`loss.backward()`。**需要清除已存在的梯度**，否则梯度将被累加在已存在的梯度。更新权重实践中最简单的更新规则是随机梯度下降(SGD)$$weight = weight - learning_rate * gradient$$使用python代码实现如下： learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 12还有一些其他的更新规则如`Nesterov-SGD,Adam,RMSPROP`等。这些规则可以在包`torch.optim`中实现，使其变得非常简单。 import torch.optim as optim create your optimizer optimizer = optim.SGD(net.parameters(), lr=0.01) #in your trainning loop: optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criter(output, target) loss.backward() optimizer.step() # does the update 12345678910111213141516关于数据 通常在处理图像，文本，音频和视频数据时，可以使用标准的Python包来加载到一个numpy数组中，然后将数组转换成`torch. *Tensor`- 对于图像，有Pillow和OpenCV包。- 对于音频，有scipy和librosa包- 对于文本，原始Python和Cython来加载，或者NLTK和SpaCy是有用的。对于视觉，创建有`torchvision`包，包含常见数据集的加载如Imagenet, CIFAR10, MNIST等和图像转换器，也就是`torchvision.datasets`和`torch.utils.data.Dataloader`。提供了巨大的便利，避免了代码的重复。 1.加载和归一化CIFAR10 import torch import torchvision import torchvision.transforms as transforms 12torchvision的输出是[0,1]的PILImage图像,我们把它转换为归一化范围为[-1, 1]的张量。 transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) trainset = torchvision.datasets.CIFAR10(root=’./data’, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=’./data’, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = (‘plane’, ‘car’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’) 1234展示一些训练图像 import matplotlib.pyplot as plt import numpy as np functions to show an image def imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.show() get some random training images dataiter = iter(trainloader) images, labels = dataiter.next() show images imshow(torchvision.utils.make_grid(images)) print labels print(‘ ‘.join(‘%5s’ % classes[labels[j]] for j in range(4))) 12定义网络并进行训练 from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def init(self): super(Net, self).init() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 5 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # wrap them in Variable inputs, labels = Variable(inputs), Variable(labels) # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.data[0] if i % 2000 == 1999: # print every 2000 mini-batches print(&apos;[%d, %5d] loss: %.3f&apos; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(‘Finished Training’) 1234在训练集上测试网络第一步，显示测试集的图片 dataiter = iter(testloader) images, labels = dataiter.next() print images imshow(torchvision.utils.make_grid(images)) print(‘GroundTruth: ‘, ‘ ‘.join(‘%5s’ % classes[labels[j]] for j in range(4))) #output: GroundTruth: cat ship ship plane outputs = net(Variable(images)) #经过神经网络的输出 _, predicted = torch.max(outputs.data, 1) print(‘Predicted: ‘, ‘ ‘.join(‘%5s’ % classes[predicted[j]] for j in range(4))) #output:Predicted: cat ship car plane 12在整个测试集上测试。 correct = 0 total = 0 for data in testloader: images, labels = data outputs = net(Variable(images)) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum() print(‘Accuracy of the network on the 10000 test images: %d %%’ % ( 100 * correct / total)) #output: Accuracy of the network on the 10000 test images: 55 % 1234相对于偶然正确率10%似乎学习到了一些东西。看看对什么类的训练结果较好。 class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) for data in testloader: images, labels = data outputs = net(Variable(images)) _, predicted = torch.max(outputs.data, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i] class_total[label] += 1 for i in range(10): print(‘Accuracy of %5s : %2d %%’ % ( classes[i], 100 * class_correct[i] / class_total[i])) #output: Accuracy of plane : 60 % Accuracy of car : 46 % Accuracy of bird : 44 % Accuracy of cat : 35 % Accuracy of deer : 38 % Accuracy of dog : 43 % Accuracy of frog : 57 % Accuracy of horse : 76 % Accuracy of ship : 71 % Accuracy of truck : 74 % 1234 在GPU上训练将神经网络移动到GPU上进行训练方法和将一个`Tensor`转换到GPU相同，这个操作会递归遍历所有的模块，将参数和缓冲区转换了CUDA张量。 net.cuda() 12同时，你也需要在每一步中把你的输入和目标值转换到GPU上: inputs, labels = Variable(inputs.cuda(),Variable(target.cuda())) ` 在网络较为庞大的情况下，GPU速度提升的更为明显。","link":"/draft/pytorch.html"},{"title":"","text":"Scrapy框架学习Scrapy简介： Scrapy是一个应用于爬取网站或者提取结构化数据的框架，具有十分广泛的应用，包括数据挖掘，信息处理或者记录历史档案。 虽然Scrapy最初是为了网站爬取而设计的，它也能应用于使用API来提取数据或者作为一个普通的网站爬虫。 scrapy 安装 scrapy安装使用Anaconda安装会较为友好,这样会解决你的依赖包安装问题。 install -c conda-forge scrapy```1234567891011121314151617181920这里稍微提一下scrapy的依赖包 lxml, 一种高效的XML和HTML解析器， PARSEL, 一个HTML / XML数据提取库，基于上面的lxml， w3lib, 一种处理URL和网页编码多功能辅助 twisted, 一个异步网络框架 cryptography and pyOpenSSL, 处理各种网络级安全需求2. scrapy使用* 创建scrapy项目在windows cmd命令下进入相应路径，输入``` scrapy startproject xxx 其中xxx是我们创建的蜘蛛的名字，后面会提到。 创建好之后的文件夹下面会有以下文件。 从一个简单例子入手 以获取网站 http://quotes.toscrape.com/ 为例，代码如下 12345678910111213141516171819import scrapyclass QuotesSpider(scrapy.Spider): name = &apos;quotes&apos; start_urls = [ &apos;http://quotes.toscrape.com/tag/humor/&apos;, ] def parse(self, response): for quote in response.css(&apos;div.quote&apos;): yield { &apos;text&apos;: quote.css(&apos;span.text::text&apos;).get(), &apos;author&apos;: quote.xpath(&apos;span/small/text()&apos;).get(), } next_page = response.css(&apos;li.next a::attr(&quot;href&quot;)&apos;).get() if next_page is not None: yield response.follow(next_page, self.parse) 将其保存为quotes_spider.py ，使用runspider命令 scrapy runspider quotes_spider.py -o quote.json 完成之后将会看到有生成quote.json 文件，包含有文本内容和作者。 12345678910111213[{ &quot;author&quot;: &quot;Jane Austen&quot;, &quot;text&quot;: &quot;\\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\\u201d&quot;},{ &quot;author&quot;: &quot;Groucho Marx&quot;, &quot;text&quot;: &quot;\\u201cOutside of a dog, a book is man&apos;s best friend. Inside of a dog it&apos;s too dark to read.\\u201d&quot;},{ &quot;author&quot;: &quot;Steve Martin&quot;, &quot;text&quot;: &quot;\\u201cA day without sunshine is like, you know, night.\\u201d&quot;},...] 当使用runspider 命令时，Scrapy找到一个定义好的蜘蛛然后启动他的爬虫框架。 这只蜘蛛首先对start_urls中的url发送Request请求,返回默认的parse方法，将response 作为参数传入。在parse方法中，我们使用CSS选择器寻找名言中的元素，产生一个包含有名言的内容和作者的字典，再寻找下一页的链接再将下一个请求放入队列并将parse作为回调函数。 这里面可以观察到Scrapy的一个主要优点就是requests加入队列和处理是异步发生的。这就以为这Scrapy不需要等待请求完成再进行处理，在此期间它能发送下一个请求或者做一些其他的事情。这也意味着即使有些请求出错了，但是其他请求也能够继续进行。 Scrapy框架也能让你完成一些爬虫设置，比如设置下载的时间间隔，限制每个ip或者域名下一定数量的请求，甚至能使用自动的流量拓展来自动设置这些参数。","link":"/draft/scrapy学习.html"},{"title":"","text":"title: 浅谈机器学习与深度学习中的算法原理(二)date: 2018-12-15 09:41:12tags: 本文意在讨论机器学习算法中的K-近邻算法和决策树算法。 一.K-近邻算法1.概述K-近邻算法，又称为KNN算法(K-Nearest Neighbor)，是数据挖掘中最简单的算法。 工作原理为：给点给一个已知标签类别的训练集，输入没有标签的新数据集后，在训练数据中找到与新训练集最邻近的K个实例。如果这K个实例的多数属于某个类别，那么新数据就属于这个类别。简单理解为：由那些离X最近K个点投票来决定将X归为哪一类。 如上图所示，绿色圆点的分类情况和我们选取的K的值有关。 当K=3时，即我们选择和绿点距离最近的三个点，此时绿点被划分到红色三角形这一类。 当K=5时，即我们选择和绿点距离最近的五个点，此时绿点被划分到蓝色正方形这一类。 2.实现用python3代码实现上述过程，先计算距离，再将距离排序，统计前K个点所出现的频率，灾后确定类别。 先空着，留坑///// 二. 决策树算法1.概述决策树(Decision Tree)是有监督学习的一种算法，同时是一种基本的分类和回归算法。分为两种：分类树和回归树。 以决定是否出门为例，我们可以画出下面的回归树。 可以看出，决策树本质是树形结构，我们通过设计一些条件来对数据进行分类。 决策树由节点和有向边组成，一般一颗决策树包含一个根节点、若干内部节点和若干叶节点。决策树的决策过程需要从决策树的根节点出发，将待测数据与决策树中的特征节点进行比较，并按照比较结果选择下一个分支，直到到达叶子节点作为最终的决策结果。 2.决策树构建 特征选择 特征选择在于选取对训练数据具有分类能力的特征，这样可以提高决策树的学习效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大的差别，则称这个特征是没有分类能力的。通常特征选择的准则是信息增益或信息增益比。 在决策树的构建中，可以通过选择不同的特征作为根节点，这样形成的决策树也都能延续下去。问题是：怎样选择更好？这就要求我们确定选择的原则，直观上来看：如果一个特征具有更好的分类能力，或者说，根据这个特征将训练集分割为不同的子集，使得各个子集在当前条件下有最好的分类，就应该选择这样的特征。信息增益（information gain）就能很好的表达这一直观准则。 在了解信息增益之前，有必要给出熵和信息熵的定义。 在信息论与概率论统计中，熵 (entropy)是表示随机变量不确定性的度量。设X是一个取有限个值的离散随机变量，概率分布为$$P(X=X_i)=p_i, i=1,2,3…$$则随机变量X的熵定义为$$H(X) = -\\sum_{i=1}^{N}p_ilogp_i$$ 在上式定义中，$p_i=0$，则定义0log0=0。通过，式中对数以2为底或以自然对数e为底，熵的单位分别称作为比特(bite)或纳特(nat)。由定义可知，熵只依赖于X的分布，而与X的取值无关，所以可将X的熵记作H(p)。 熵越大，随机变量的不确定性就越大，从定义可以验证$$0\\leq H(p)\\leq logn$$当随机变量只取0,1时，X的分布为$$P(X=1)=p,P(X=0)=1-p,0\\leq p \\leq 1$$熵为$$H(p)=-plog_2p-(1-p)log_2(1-p)$$作出H(p)图像如图所示，单位为比特。 当p=0或p=1时H(p)=0， 随机变量完全没有不确定性。当p=0.5时，H(p)=1，熵取值最大，随机变量的不确定性最大。 条件熵H(Y|X)表示在一直随机变量X的条件下随机变量Y的不确定性。定义为X给定条件下Y的条件概率分布的熵对X的数学期望。$$H(Y|X)=\\sum_{i=1}^{n}p_iH(X=x_i)$$这里，$p_i=P(X=x_i),i=1,2,…,n$ 信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少程度。 信息增益 特征A对训练数据集D的信息增益为g(D,A)，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即$$g(D,A)=H(D)-H(D|A)$$一般的，熵H(Y)与条件熵H(Y|X)之差成为互信息(mutual information)。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。 显然的，信息增益表示特征A对数据集D分类的不确定性减少程度，不同的特征具有不同的信息增益。信息增益大的特征具有更强的分类能力。 设训练数据为D，|D|表示其样本容量，即样本个数。设有K的类C_k,k=1,2,\\cdots ,K,|C_k|为属于类C_k的样本个数，$\\sum_{k=1}^K|C_k|=|D|$即特征有个不同的特征.即特征A有n个不同的特征{a_1,a_2,a_3,\\cdots, a_n}根据特征的取值将划分为个子集,根据特征A的取值将D划分为n个子集D_1,D_2,D_3,\\cdots ,D_n,|D_t|为为D_i的样本个数，的样本个数，\\sum_{i=1}^n=|D|。记子集。记子集D_i中属于类中属于类C_k的样本集合为的样本集合为D_{ik}，即，即D_{ik}=D_i\\bigcap C_k,|D_{ik}|为为D_{ik}$的样本个数，信息增益的算法如下。 输入：训练数据集D和特征A; 输出:特征A对训练数据集D的信息增益g(D,A). (1)计算数据集D的经验熵H(D)$$H(D)=-\\sum_{k=1}^K \\frac{C_k}{|D|}log_2\\frac{|C_k|}{D}$$(2)计算特征A对数据集D的经验条件熵H(D|A)$$H(D|A)=\\sum_{i=1}^{n}\\frac{|D_i|}{|D|}H(D_i)=-\\sum_{i=1}^{n}\\frac{|D_{i}|}{|D|}\\sum_{i=1}^{n}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_{i}|}$$PS:在特征的每个子集中不是简单求和，而是加权求和 (3) 计算信息增益$$g(D,A)=H(D)-H(D|A)$$ 信息增益比 信息增益值的大小是相对于训练数据集而言，没有绝对的意义。在分类问题困难时，也就是训练数据集的经验熵大的时候，增益值也会偏大。所以使用信息增益比(information gain ratio)可以对这一问题进行校正。 特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益g(D,A)与训练数据集D的经验熵H(D)之比：$$g_R(D,A)=\\frac{g(D,A)}{H)(D)}$$ 3.决策树的生成 ID3 生成算法 方法原理:从根节点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归地调用以上方法，构建决策树;知道所有特征的信息增益均很小或没有特征可以选择为止。最后得到决策树。ID3相当于用极大似然法进行概率模型的选择。 算法： (1)若D中所有实例属于同一类$C_k$，则T为单节点树，并将类$C_k$作为该节点的类标记，返回T; (2)若A=∅，则T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类标记，返回T; (3)否则，计算A中各特征对D的信息增益，选择信息增益最大的特征$A_g$; (4)如果$A_g$的信息增益小于阈值$\\epsilon$，则置T为单节点树，并将D中实例数最大的类$C_k$作为该节点的类标记，返回T; (5)否则，$A_g$的每一个可能值$a_i$，依$A_g=a_i$将D分割为若干非空子集$D_i$,将$D_i$中的实例数最大的类作为标记，构建子节点，由节点及其子节点构成树T，返回T; (6)对第i个子节点，以$D_i$为训练集，以A-{$A_g$}为特征集，递归地调用步(1)~步(5)，得到子树$T_i$,返回$T_i$。 ID3算法只有树的生成，所以该算法内容生成的树容易出现过拟合。 C4.5的生成算法 C4.5算法与ID3算法相似，进行了一些改进，在生成树的过程中，用信息增益比来选择特征。 4.决策树的剪枝…天坑","link":"/draft/浅谈机器学习与深度学习中的算法原理-二.html"}],"posts":[{"title":"deep learning ai notes","text":"Coursera Enda Wu: Courses in this sequence(Specialization): Neural Networks and Deep Learning Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization. Structuring your Machine Learning project. Convolutional Neural Networks. Natural Language Processing: Building Sequence Models 1.Neural Networks and Deep Learningweek 1Relu(rectified linear unit) $max(0,w^Tx+b)$ Different types of neural network: CNN(Convolutional Neural Network) used often for image application and RNN(Recurrent Neural Network) used often for one-dimension sequence data such as text transcript. Hybrid neural network architecture for autonomous driving. Structured and Unstructured data Structured data refers to things that has a defined meaning, such as price and age. It is easy to be represented by two dimension tables. Unstructured data refers to things like pixel, raw audio, text, which is difficult for computers to understand. outline of this course week 1: Introduction week 2: Basic of Neural Network programming week 3: One hidden layer Neural Networks week 4: Deep Neural Networks week 2 logistic regression is an algorithm for binary classification.","link":"/2018/12/11/courseradl/"},{"title":"Markdown的基本用法介绍","text":"markdown语言是一种纯文本格式语言，通过简单的标记语法，它可以使普通文本具有一定的格式。本博客使用的就是该种语言。为此，我们有必要熟悉一下这种语言，下面我们花5分钟时间来简单了解一下吧。 一. 标题12345# 一级标题## 二级标题### 三级标题...###### 最多能支持六级标题 这里需要注意的是，#后面要跟个空格再写文字。 二. 字体 加粗 在要加粗的文字左右分别用两个**包起来。 或按快捷键Ctrl+B 斜体 在要倾斜的文字左右分别用一个*包起来。 或按快捷键Ctrl+I 斜体加粗 加起来就是左右三个* 啦 或快捷键两个先后使用 删除线 删除内容左右分别用两个~~包起来。 或快捷键Alt+Shift+5 三. 引用在引用的文字前加&gt;即可。引用可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;，不限制数量。 这是引用内容 这也是引用内容 四.分割线 使用三个或三个以上的-或是*。 效果完全相同 五. 图片1234![alt](图片地址 &apos;&apos;title&apos;&apos;)![blockchain](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;区块链&quot;)alt是图片下面显示的标题，title是鼠标移动到图片上显示的文字，title可省略 六. 超链接12[超链接名](超链接地址 &quot;超链接title&quot;)title可省略 百度 七.列表 无序列表 用 -、+、*任何一种效果相同，注意后面跟空格再加文字。 1- 测试1 测试2 有序列表 用数字加.，序号和内容之间有空格。 列表嵌套 上一级和下一级之间敲三个空格 一级无序 二级无序 三级无序 一级有序​ 二级无序​ 二级无序 八. 表格123456789101112131415表头|表头|表头-|:-:|-:内容|内容|内容内容|内容|内容第二行分割表头和内容文字默认居左，两边加：居中，右边加：居右注：原生的语法两边都要用|包起来实例：姓名|技能|排行--|:--:|--:刘备|哭|大哥关羽|打|二哥张飞|骂|三弟 姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 九.代码单行代码：代码之间分别用一个反引号`包起来 create database heros 代码块：用三个反引号`包起来,且引号要单独占一行 1234#include&lt;stdio.h&gt;void main{ printf(&quot;hello world&quot;);} 十. 流程图123456789​```flowst=&gt;start: 开始op=&gt;operation: My Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op&amp; 123456789101112```flowst=&gt;start: 开始op=&gt;operation: My Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op&amp; ` 后续再编辑过程中若还有新用法持续更新…","link":"/2018/12/08/markdown基本用法/"},{"title":"labelme","text":"labelme的安装和使用因为最近是本科毕业设计开题，我的毕设题目是融合遥感影像和GPS轨迹数据的道路提取，涉及到深度学习来提取影像信息，数据源需要用labelme来进行标注。 labelme是MIT开源的一款标注软件，官方的github地址为https://github.com/wkentaro/labelme. 一. 安装过程本文介绍labelme在windows下的安装过程。 在Windows系统下，首先安装anaconda, 官网下载 https://www.anaconda.com/ ，博主这里下载的是3.7版本，安装过程中记得把添加到系统路径勾上，否则就安装完成之后手动添加。 安装完成之后，开始菜单打开anaconda prompt, 输入以下命令。 12345# python3conda create --name=labelme python=3.7activate labelmeconda install pyqt # pyqt5 can be installed via pip on python3pip install labelme # use &apos;pip install&apos; instead of &apos;conda install&apos; 安装至此结束，是不是很简单呢。 二.使用方法Labelme可对图像进行矩形标注和多边形标注，生成的文件是json文件。 在anaconda prompt 窗口下继续输入命令： labelme 即可打开labelme的图形界面。 仔细观察的话，可以发现左上角是一个Lena.jpg哦。","link":"/2018/12/11/labelme/"},{"title":"Say goodbye to 2018","text":"2018年还有20多天结束了，刚好在这天迎来了自己20岁的生日，人生这么快就过去了六分之一。每思致此，我还有些惆怅。 正好最近在研究 hexo+github 搭建自己的个人博客，就以此作为博客的第一篇。 总的来评价，我的2018年过的还是比较有意义的。年头我就想要在这一年里面把之前没有时间去完成的事情多完成几件，尽量去尝试多种不同的有意义的事情。 上半年主要是上专业课+学习爬虫，虽然爬虫知识到现在为止漏洞还是很多。这门兴趣我是在大学生科研阶段培养起来的，偶然网上看到静谧大神，跟着他的博客一步步学习下去，有一点小小的成果和经验，但是尚缺的还是从一个系统来整体学习。在这段时间里面，我记得当时准备考研的同学已经开始着手准备了，那时的我也是准备考研的，但是我一点不慌，每天也是跟着他们去图书馆，看博客、读爬虫书、亲自实验，玩的有滋有味。 三月份的时候接触到了一群玩街头健身的朋友，每天基本无特殊情况的话都会在信操一起锻炼。接触的途径是有一天晚上闲的无聊去东湖散步，突然想到咱们学校有没有那种健身社团，于是打开qq群在附近搜索“武大健身”关键字，然后就加入了组织。在这个圈子中，大家三观都很正，而且都是那种积极上进的人，无论在健身还是学习方面，所以自己还是比较喜欢这里的。 一直到暑假前夕，我才开始关注一下未来的出路了，当时自己还在张同学的CS鼓吹论下考虑要不要转浙大计算机，也了解了一下北航、复旦、浙大、中科大这些学校的计算机专业，都蛮强的 (这是废话)，甚至还一时冲动还在某二手平台买了408专业课的复习资料准备开始复习，后来由于个人懒惰原因没能坚持读下去。 为了调适心情（玩+赚钱），我参加了某研学公司去参加带小孩子夏令营兼职了，5天湖南游，大夏天舍命陪孩子玩儿，赚了几百块钱，那时候头哥和zy也在湖南的公司实习，但是由于我这边比较忙连见面时间都没有。完成兼职之后还是没开始复习，又头铁去参加了感知成都的暑期实践，成都毕竟一直以来也是我想去的地方，有美食，美女，美景还有萌萌的大熊猫，一个礼拜的成都之行还是蛮巴适的。 再后来已经到了7月10几号了，开始紧张起来，一开始准备在学校复习考研的，但是每天感觉睡眠不好，也可能由于夏天到了心思静不下来，想回去学习了。回去之后果不其然，睡眠挺好的，每天睡觉睡的起不来，懒惰的要死，低效率的学了两个礼拜之后又在7月底早早的来到了学校。当时香蕉哥正一起复习，那段时间是整个一学年的高效时期，每天生活很规律，学的很有劲，而且每天还能抽出时间一起锻炼。 开学后，一个转折点出现了。那段时间我们大学生科研要结题了，就去找桂老师聊了一聊了。那天聊结题的内容什么的我忘了，但是记得的是就是这次聊天把我从考研拉回了出国(哎，真是一个善变的男人)。当时花了几天考虑了一下，毕竟之前复习的还是卓有成效的，记得是在欢乐谷的S1000过山车上考虑清楚的。 从那以后我就开始准备各种材料，看学校信息，准备德国的留学审核部审核(好像到现在为止还没开始复习)。每天写材料写的痛苦不堪，拿给czy改的时候又被diss好久，导致我很失落那段时间。但是还好，虽然英文写作是比较菜，但是慢慢磨，总会有个材料出来。拿着这份材料交了几个学校，录了一个港理工(我记得还把academic后面多加了一个e)。本来准备拿这个学校保底的，但是这货居然让我12月份交留位费，上了张鬼子的当，然后又提交了几个学校，这些还在等结果，希望这个月能再收到几个offer稳稳军心吧，当然自己的梦校还是TUM。 其实每条路都有存在的意义，坚持走完都有成果的。无论未来碰到什么石头，都一定要自信的走下去，不动摇。Follow your heart and achieve your goals. 2018年12月6日 于 武汉大学信息学部图书馆","link":"/2018/12/06/Say good bye to 2018/"},{"title":"德国留学APS介绍及遥感复习经验","text":"APS复习经验1.APS简介德国驻华使馆文化处留德人员审核部(APS)，是由德国驻华使馆文化处和德意志学术交流中心在北京共同合作成立的服务机构。 APS是中国学生前往德国留学的大门，职责是对有意赴德留学的中国学生(不含港澳台学历)进行资历审核。申请德国的博士不需要APS审核。 APS内容包含笔试和面试两个部分，笔试中会有5题左右的专业相关的题目在规定时间内进行解答，面试中会有三个考官对你的专业知识进行提问，提问内容涉及成绩单中所学科目。 具体设置这个审核的原因据说是因为早些年之前因为有国人学术造假问题，所谓前人拔树后人遭殃，德意志从2001年开始就审核我国学生的学历真假，仅在蒙古、越南和中国实行，所以说也并不是一件光荣的事情。 2. APS申请可能因为德国人做事比较严谨的原因，APS申请过程需要的材料也很繁琐。 首先需要进入APS的官网，https://www.aps.org.cn/zh，语言看不懂德语的话可以设置为中文，进去注册账号，填写相关信息，然后开始按照要求准备申请需要的材料。 该图是申请面谈过程中的2018年的材料清单，由于材料可能会每年发生变化，所以请申请者自行查看最新的申请步骤，然后准备相关材料。 若是小学毕业证和初中毕业证丢失或者没有，可以写一份证明去所毕业小学初中加盖公章替代。高中毕业证和大学花名册（在学校档案馆开具）则还需要花几百块钱在公证处公证并翻译英文。有人问到能不能异地公证问题，不好统一回答，当时我在武汉的时候是可以公证家乡的高中毕业证的，具体情况请电话咨询公证处。一般需要一周左右的时间可以取到公证件。 公证完成之后请将审核费用去当地银行汇款到审核部提供的账户上面并要求柜员帮忙开取汇款证明。 材料准备完成之后，就是邮寄了。选择一个自己比较方便的快递或者中国邮政都可以，他们审核部那边收到邮寄件之后的1个月再登录官网就能看到自己出了一个审核号，但是这并不代表你的材料齐全了，若是材料缺失可能他们会联系你继续补材料，所以不必太过于担心。 至于选择面试地点的话，不要一开始就选择成都、广州，因为这两个地方每年审核时间不固定，排队可能排到天荒地老。江苏、安徽、浙江、上海等地需要选择上海作为审核地点，其他地方选择北京就好。这里面需要注意的是，在每年2月底的时候关注一下官网（可能不固定，建议每天都看看以免错过时间），首页中会有新闻说安排成都面试，这时候你可以发邮件将自己的审核地修改为成都（据说难度会比北京低很多），这个邮件可能并没有人回复你，但是在发邮件的1到2个礼拜内就会接到面试通知跟你确认相关事宜。 关于排队时间问题，不同专业排队时间不同，热门专业（机械）和冷门专业排队时间最长，这个就是看运气的问题了，我的专业当时排了半年而已。（手动滑稽）一般专业排队时间都可能3-6个月不等，所以建议大家合理安排时间。 3. 复习准备准备复习的过程希望大家能一提交申请就开始复习，特别是一些热门专业对方懂得可能比较多问的可能也比较深入。然后冷门专业的话可以稍微晚一点，毕竟排队都不知道排到什么时候。我是一个小众学科，在接到电话之后还有两个礼拜的时间内开始复习的，希望大家不要学我。 复习方法就是先从大三大二的课程开始准备，内容相似的学科可以一起准备，用分块复习法，还要注意自己考得最好和最差的科目，像一般的高数、大物这种课程被提问到的概率比较小，除非你自己本身就是物理、数学专业的。每门课复习的时候可以先总结这门课讲了什么，然后从这里开始延伸开来，保证自己延伸开来的内容都能解释的通，最后可以用一个小例子来做说明，也可以结合画图、手势等操作让面试官理解你在说什么。若是大四下学期参加面试还有可能被问到自己的大四课程以及毕业设计内容，需要回答毕设和自己之前学的科目有什么联系等。建议大家复习时候用中英结合的方式，这样能更好的帮助记忆，科目名称用不同颜色标注表示重要程度。 由于大家的专业不同，可以去abcdv论坛上面看相关的经验。 4. 遥感复习本人是遥感科学与技术专业，方向摄影测量，但是结合本专业其他人的面试经验，被询问到遥感的概率还是蛮大的，可能本身因为考官对于遥感知识了解更多而且本来专业就写着是遥感。 以下是自己复习时候针对自己专业课的准备，相似专业的同学可以作参考。 Technique of Virtue Reality This course mainly taught us about the development of virtual reality recent years and the hardware and software applied in this technology. The hardware included the VR headset, VR glasses and so on. And we were formed into groups to use the software 3dmax and unity 3d to complete a task that a small ant wandering in an office, in which were the office chairs and tables. We could use the keyboard to control the ant’s movement and the surroundings changes according to the location and perspective of ant. That was really an interesting and creative curriculum in my mind. Remote Sensing Section Remote Sensing Image Interpretation This course Remote Sensing Image Interpretation is to analyze, recognize and judge by the feature information of various recognition targets provided by satellite images, and finally achieve the goal of recognition targets or phenomena. The interpretation could be divided into visual interpretation which is conducted by human beings and the computer interpretation. The visual interpretation required human to have rich experience toward the specific target in a remote sensing image. And the computer interpretation was combined with pattern recognition or artificial intelligence technology. The principle of interpretation is detecting objects in the images based on the extraction of object features and interpretation experience. Question may be asked: Classification: Supervised classification is based on the prior knowledge of the classification of ground objects in the sample area of remote sensing images. Unsupervised classification is a process in which attributes of ground objects in remote sensing images do not have prior knowledge, and “blind classification” is carried out purely on the basis of statistical differences of different spectral data combinations. Principle and application of Remote Sensing Remote Sensing is the acquisition of information about an object or phenomenon without making physical contact with the object. This technology is used in numerous fields, including geography, land surveying and most earth science disciplines (hydrology, ecology, meteorology oceanography, geology). This often refers to observe the earth surface of the atmosphere from out of space using satellite (space borne) or from the air using aircrafts(airborne). This technology uses a part or several parts of the electromagnetic spectrum. (It records the electromagnetic energy reflected or emitted by the earth surface.) from which people to interpret the images. Workflow: The emitted or reflected electromagnetic from the object àthrough the atmosphere à sensors get data à data processing by computers à information extracted by software with expert’s experienceàapplication object spectrum characteristic means the object emit or reflect electromagnetic characteristic. Atmosphere: electromagnetic is reflected, absorbed, or scattered by atmosphere. Atmospheric window: A band of electromagnetic radiation with a high transmission that is less reflected, absorbed, or scattered through the atmosphere. Factors affecting the reflectivity of the ground object: wavelength (μ), angle of incidence 入射角(θ), surface color and roughness (ε) 3 high: high spatial resolution, high spectral resolution, high temporal resolution The data processing method: radiometric and geometric correction Information extraction: spectral feature, spatial feature, time feature, polarization feature The characteristics of RS: the process is fast, less limitation and abundant information and the information obtained is true and objective. 波段长度 ​ Wavelength: 无线电波 radio wave: range from 10^-3 meter to 3000 meters 微波 microwave: range from 0.1 centimeter to 1 meter 红外线 infrared ray: range from 7.8*10^-7 to 10^-3 meter, it has obvious heat effect 可见光 visible light: range from 4000 to 7600 *10^-10 meter 紫外线 ultraviolet ray: range from 10 to 380 * 10^-9 meter 大气层：对流层，平流层，电离层和外大气层 Troposphere ,stratosphere, thermosphere, exoatmosphere 地球同步轨道卫星 geostationary orbit satellite. 36000km Ground object -&gt;images -&gt; geometric information -&gt; model reconstruction-&gt;location ​ -&gt; radiometric information-&gt;interpreting-&gt; property Image point displacement: topographic displacement, curvature of earth, atmospheric refraction The purpose of georeferencing (geometric correction) is to transform the image coordinate system, which may be distorted to a specific map projection. The image process involves the transformation of a real-3D scene geometry to a 2-D image. Means: Based on Rational Function Model, Polynomial model. Radiation correction: The process of eliminating various noises added to the radiant energy output by the sensor during photographying. Reason: Sensor performance, atmospheric scattering and absorption, terrain and lighting conditions. Means: radiometric calibration, establishing a quantitative relationship between the numerical quantized value of the signal output by each detector element of the sensor and the actual radiation value in the corresponding pixel of the detector. Visual interpretation requires: rich experience, solid professional knowledge. Related materials. Automatic classification: Make the computers simulates human vision to extract information from satellite images. The precision evaluation was carried out for classified image by confusion matrix. Laser remote sensing Laser remote sensing is the general term to describe the procedure to gain physical information on systems from a large distance with the aid of laser. The principle is simple: light from a laser strikes the system of interest and the returning light is detected by a telescope and analyzed. LIDAR (light detection and ranging) Active remote sensors. The characteristic of LIDAR: lidar can partially penetrates vegetation and measure the ground and non-ground at the same time. Less affected by the weather and can work at any time. Does not need many control points. Doesn’t need special light or solar elevation angle, without the restriction of day, able to detect small target. Diffraction: Diffraction is a physical phenomenon in which waves deviate from their original straight line propagation when they encounter obstacles. Interference: Interference is a phenomenon that when two or more columns of waves overlap in space, they overlap to form new waveforms. Application: tunnel deformation monitoring, 3-dimensional city modelling, protection of old buildings. (the location, size and texture) 点云配准 point cloud registration The differences between photogrammetry and LIDAR: The sensors are different, optical sensor, laser Low cost, high cost. Panchromatic, multispectral, hyperspectral; infrared band. Take weather affect into consideration; all-weather all-time Lack highly automated software; High precision, high density, discrete points may be not our interests; Photogrammetry Section Analytical Photogrammetry This course was the first photogrammetry course during my undergraduate study. Photogrammetry is the science of making measurement from photographs. The input to photogrammetry is photographs, and the output is typically a map, a drawing, a measurement, or a 3D model of some real-world object or scene. Many of the maps we use today are created with photogrammetry and photographs taken from aircraft. This course mainly referred to the basic principles of Analytical Photogrammetry processing and the photogrammetry applications in geo-science. In the course practice, we applied the photogrammetry methods to professional survey services on our campus based on unmanned aerial vehicle images. Close Range Photogrammetry Close-range photogrammetry is a branch of photogrammetry that determines the shape and motion of a target by means of photography. It was widely applied on industrial photogrammetry, biomedical photogrammetry and protection of ancient buildings. The basic principle is identical with aerial photogrammetry, as well as the analog process method, the analytical process method, the digital image processing method. On the other hand, the purpose is different. The aerial photogrammetry focused on the ground surface while the close range pay more attention to the size or motion state of object, not the absolute location. The subjects in close range photogrammetry are various objects. Take temples and vehicles for example. The photography method is different too. The aerial takes the vertical photography method while the close range usually take the normal case method. Modern Photogrammetry This course mainly introduce that the practice of photogrammetry today bears little resemblance to that during its formative years in the last century. While the basic mathematical principle of photogrammetry remains unchanged, their implementation and application for production purpose have drastically changed. The photogrammetric equations, formerly embodied in precise analog solutions, now exist as programs in general-purpose digital computers; the implications of this advance are still being explored. This subject is not a new subject, it has some repeating contents with the analytical photogrammetry, digital photogrammetry, close range photogrammetry and satellite photogrammetry. The characteristic of this course was bilingual language teaching. Satellite Photogrammetry This course taught about the sensing system which is space borne, it is called the satellite photogrammetry. Satellite photogrammetry has slight variations compared to photogrammetric applications associated with aerial frame cameras. The images are taken with high-resolution CCDD cameras coupled large lenses to take pictures of the ground right below them as they pass over. The amount of information dealt with is very large as images of very large scenes are taken from the satelites. The advantage: high altitude with attendant wide coverage. Freedom from aerodynamic motion which attend heavier than aircraft. The opportunity to photograph areas of earth that are accessible only with difficulty with conventional aircraft. Disadvantage: necessity of operating the camera in space environment. Problem of image motion compensation because of high speed of satellite. Course Design of Digital Photogrammetry Remote Sensing Image Interpretation Course Practice Course Practice of Close Range Photogrammetry The difference among these photogrammetry methods: important! In Aerial Photogrammetry, the camera is mounted in an aircraft and is usually pointed vertically towards the ground. Multiple overlapping photos of the ground are taken as the aircraft flies along a flight path. The aircraft traditionally have been fixed wing manned craft but many projects now are done with drones and UAVs. Traditionally these photos were processed in a stereo-plotter (an instrument that lets an operator see two photos at once in a stereo view) but now are often processed by automated desktop systems. In Terrestrial and Close-range Photogrammetry, the camera is located on the ground, and hand held, tripod or pole mounted. Usually this type of photogrammetry is non-topographic - that is, the output is not topographic products like terrain models or topographic maps, but instead drawings, 3D models, measurements, or point clouds. Everyday cameras are used to model and measure buildings, engineering structures, forensic and accident scenes, mines, earth-works, stock-piles, archaeological artifacts, film sets, etc. In the computer vision community, this type of photogrammetry is sometimes called Image-Based Modeling. Digital photogrammetry is a well-established technique for acquiring dense 3D geometric information for real-world objects from stereoscopic image overlap and has been shown to have extensive applications in a variety of fields. Aerial photogrammetry refers to the collection and processing of imagery captured from an aerial or orbital vehicle. Close-Range photogrammetry (CRP) refers to the collection of photography from the ground or some lesser distance than traditional aerial photogrammetry and is becoming increasing popular and accessible due to new, easy to use software and digital cameras. Non-metric, off-the-shelf digital cameras can be used along with relatively inexpensive, or in some cases free, open-source software, to extract and process highly accurate and detailed 3D models of real-world objects. Course Design for Analytical Photogrammetry In the course practice, we applied the photogrammetry methods to professional survey services on our campus based on unmanned aerial vehicle images. Firstly, … Digital Photogrammetry In recent years, with rapid development of digital technology, photogrammetry has also been applied to digital images, which may be generated directly from electronic cameras or scanned from film imagery. The use of images in digital form offers distinct advantages in processing and automation. Digital image processing can be used to alter the image in very precise ways and make it more useful. If the image is ‘examined’ by a computer, many of the operations we think of as requiring a human can be performed automatically. 确定同名核线的方法：基于影像几何纠正的核线解析关系；基于共勉条件的同名核线几何关系。 Other Section: German as the second Foreign Language (1) I choose this free selective course because I am interested in German and I want to pursue my master degree in Germany. This course enabled us to master the German pronunciation standard, can spell the German words, sentences. I have learned the basic knowledge of daily conservation in German, knew the general situation of German, the local conditions of each state, and so on. To be frankly, this course was a little difficult for me, but the exam is easy so I got a wonderful mark. Digital Image processing: This course introduces the basic concepts and methodologies of digital image processing. The covered topics include image enhancement, high dimensional spectral analysis, spatial and frequency domain linear filtering, nonlinear image filtering, binary image processing, edge detection, image segmentation, feature extraction. Image enhancement belongs to image pre-processing methods, the objective of image enhancement is highlight useful information and eliminate noise. methods: contrast improvement and image sharpening. Feature extraction include shape feature, color feature, texture feature and so on. Image segmentation partitioning a digital image into multiple segments. This is used to locate objects and boundaries in images. Is the process of assigning a label to every pixel in an image such that pixels with the same label share the certain characteristics. The Fourier transform decompose an image into its sine and cosine components, the output of the transformation represents the image in the frequency domain, while the input image is the spatial domain equivalent. Histogram equalization is a technique for adjusting image intensities to enhance contrast. Pixel intensities range from 0 to L-1 P_n = number of pixels with intensity n / total number of pixels n=0, 1, …, L-1 The histogram equalized image g will be defined by ​ where floor() rounds down to the nearest integer. Digital images are discrete representation, quantized spatially by the pixel sampling geometry and in intensity by quantization into some number of intensity levels. Computer Graphic Computer Graphics is a study of the hardware and software principles of interactive raster graphics. Topics include an introduction to the basic concepts, 2-D and 3-D modeling and transformations, viewing transformations, projections, rendering techniques, graphical software packages and graphics systems. Students will use a standard computer graphics API to reinforce concepts and study fundamental computer graphics algorithms. Database This course taught us about the fundamental of database design, modeling system, data storage, and the evolving world of data warehousing, governance and more. A database is an organized collection of data, generally stored and accessed electronically from a computer system. Access to this data is usually provided by a database management system, consisting of an integrated set of computer software that allows users to interact with one or more database and provides access to all of the data contained in the database. The DBMS software additionally encompasses the core facilities provided to administer the database. The last year Section General practice of 4d Product Production This practice is a comprehensive application of the professional knowledge, through which I have a general understanding of the process of producing DEM, DOM, and DLG, however the DRG is not produced in this practice. In this practice, we used the two software (VirtuoZo &amp; DPGrid) DEM: Digital elevation model—is a 3-dimensional computer graphics representation of a terrain’s surface—commonly of a planet—created from a terrain’s elevation data. (DEMs are often used in geographic information system, and are the most common basis for digital produced relief maps, while a DSM may be useful for landscape modeling) DLG: Digital line graph is a cartographic map feature represented in digital vector form that. DOM: digital orthophoto model—are scaled aerial photographs, which can be used (among other things) as a base map in a GIS or as a tool to revise digital line graph and topographic maps. The procedure used to create digital orthophotos, called ortho-rectification, requires aerial photographs and digital terrain model as inputs. ’’ Conventional aerial photographs have limited use in GIS because they are not true to scale. When you look at the center of an aerial photograph, your view is the same as if you were looking straight down from the aircraft. But as you look toward the edges of the photograph, the view of the ground is no longer straight down, but from an angle. This is called a central perspective projection; scale is true at the very center of the aerial photograph, but not elsewhere. In order to create a scale correct photograph that can be accurately measured, an orthographic projection is necessary, in which the view is straight down over every point in the photograph. The TIN surface is used to orthogonally rectify the scanned image file. By combining the two data sources, each image pixel has a known position and intensity value. In the rectification process, the intensity value for each pixel is re-sampled using a space resection equation, removing image displacements caused by central perspective projection, camera tilt, and terrain relief. The individual photographs are then clipped and seamlessly joined together over the entire study area. The result is a digital image that combines the image characteristics of a photograph with the geometric qualities of a map–a true to scale photographic map. The typical digital orthophoto is a quarter quadrangle image cast in the Universal Transverse Mercator projection. Ground/pixel resolutions can be as fine as 1 meter. ‘’ DRG: Digital raster graphic is a digital image resulting from scanning a topographic map for use on a computer. The raster image usually includes the original border information. The map file is UTM projected and georeferenced to the surface of the earth. DRG’s are regularly used in GIS applications. In this 4d production workflow, we first collect and organize our filed data, then build a new survey area in the software. Set the camera parameters and control point parameter, import the images and build the model, then we use the relative orientation and absolute orientation function in the software to generate epipolar image. Then we could obtain the DEM, DOM, DLG. And in the last we could slightly revise or mosaic the results. graduation project My graduation project title is “Research on Road Network Extraction Method from satellite Images”. Application: As a significant role for traffic management, city planning, road monitoring, GPS navigation and map updating, the technology of road extraction from ES image has been a hot research topic in recent years. The road in the satellite images has the following features: Geometric features: a road has a stripe feature its width does not suddenly vary much and its length is not as short as its width. Photometric feature (radiation feature): the gray values or colors of roads are relatively consistent and change slowly, but they are very different from the neighboring non-road areas such as trees and buildings. Topological features: general a road has intersections and the network is not suddenly interrupted. Texture features: textures in an image have the regional characteristics, which are a kind of visual features to reflect the homogeneity phenomenon in the image. Different road features in an image have different properties for road extraction. I use GF-2 data in my graduation project, which is the first optical remote sensing satellite in China, with a spatial resolution superior to 1m for panchromatic and 4m for multispectral. In this project, I trained a convolution neural network to extract the road network automatically. The neural network could select the features by itself and attain a perfect result. Before I trained my neural network, I labeled the images, extracted the road in the images manually to generated mask images. In this project, I mainly referred the digital image processing methods, like the image crop, image mosaic, image dilation, and image filter etc. (Refer to others’ network, use pytorch deep learning frame.) Road extraction from satellite images has been a hot research topic in the past decade. It has a wide range of applications such as automated crisis response, road map updating, city planning, geographic information updating, car navigations, etc. Plain survey: Effects: Earth curvature correction, atmospheric refraction. This course briefly introduced the basic of geodetic survey. During the course, we learn how to use total station to complete the control survey and the principle of height measurement using dumpy level. Survey Section: Geodetic survey: Geodetic surveying is a process of surveying in which the shape and size of the earth are considered. This type of survey is suited for large areas and long lines and is used to find the precise location of basic points needed for establishing control for other surveys. In geodetic surveys, the stations are normally long distance apart, and more precise instruments and surveying methods are required for this type of surveying. Cadastration: The cadastral survey includes land tenure surveys and cadastral survey. The cadastral survey is based on the legal procedures prescribed by the state, based on the land registration application. Through land ownership surveys and cadastral surveys, the ownership, boundaries, area, use and location of each land will be ascertained and data such as cadastral surveys and maps will be formed to make land registration and certification. Engineering Surveying: Engineering surveying mainly refer to the civil engineering work. Surveying engineers measure the physical features of the Earth with great precision. They verify and establish land boundaries and are key players in the design and layout of infrastructure, including roads, bridges, and cell phone towers. Their tools range from remote-sensing systems to transits, and by the time you graduate, you will know how to use them all. Error processing of Spatial Data: Spatial measurement is the process of acquiring the shape, size, and geometry of the earth’s surface (including various objects on the ground) and their spatial locations. This course mainly taught about the post-survey adjustments which refer to a series of statistical adjustments applied to survey data prior to data analysis dissemination. Typically include data editing, missing data imputation, weighting adjustments and disclosure limitation procedures. Accuracy versus precision Accuracy is the dispersion of measurement results when repeating measurements. Precision is the proximity of the measurement result to the true value. We often apply the least squares adjustment to the adjustment. The principle is to minimize the square of the deviation. CX – W =0 where C : coefficient matrix of dimension r x n, W: constant vector of dimension r, And r : number of conditions. The least squares criterion for solving the observation equations with condition equations is well-known as V(T)PV = min, 3S Section GPS: There are 3 main components to the GPS system, the components are known as segments, as follows: \\1. Space Segment – the satellite, also known as space vehicles. \\2. Control Segment – ground stations run by the DOD \\3. User Segment - all users and their GPS receivers. The GPS was originally envisioned for military use, it soon became obvious that there would be numerous civilian applications as well. For each required level of accuracy, receiver characteristics and the measurement techniques employed are different. (For a hiker in the woods or a soldier in the field, a position within about 10 meters would be enough, for geodetic land surveying, accuracy requirements are 1 centimeter or less) Each satellite transmits information at 2 carrier frequencies, called L1 and L2. The carriers L1 and L2 are pure radio waves and in themselves contain no information. The GPS data are superimposed onto the L1 and L2 carrier frequencies. These data types are called the Navigation Message, the C/A (coarse acquisition) Positioning Code and the P(precision) Positioning Code. The P code is encrypted and is available to the U.S and allied military. The GPS system determines your location using a surveying technique known as “trilateration”, this refer to using distance from several known locations to compute the coordinate of an unknown location. The GPS receiver determines its position using three satellites to triangulate its 3D position Error: atmospheric effects. GIS: Geographic Information System: A computer-based technology and methodology for collection, managing, analyzing, modelling and presenting geographic data for a wide range of applications. In this course, we used GIS applications as tools to create interactive queries, analyze spatial information, edit data in maps, and present the results of all these operations. In the GIS practice, we scanned the map to digitalize it, and generate the Digital Line Graphic as the data input. Then applied overlay analysis and buffer analysis to selection a good site for stores, considering the traffic line, the distance to settlement place, and density of population. Key points： Digital Photogrammetry (分低) Analytical Photogrammetry (摄影测量的基本) Remote Sensing!(光谱曲线，多次考察) 一些该专业学生被经常提问到的考点：（不区分学习方向！！） 光谱曲线地物判别、波段范围和选择、数字图像处理滤波、大气影响、遥感应用 时间准备仓促，有些地方可能准备的不是很全面，以上内容仅供参考。希望大家准备的时候可以使用谷歌、维基百科等工具辅助复习。 对于大部分努力的同学来说，aps面试确实不算什么，甚至对于211以上的院校通过面试的门槛会降的更低，一般面试结果在第二天就能出来，碰到双休就延迟到周一，届时可以在官网查看。 5.写在后面留学千万条，合适第一条。择校不规范，自己两行泪。 留学需要考虑的因素很多，比如工作读博前景，优势专业，生活舒适度，国家稳定情况，留学费用等等。德国留学的话总的来说性价比很高，毕竟大部分州都免收学费，相比于其他收学费的欧洲国家的话是个不错的选择。但同时也要考虑到在德国毕业之后的就业情况，当地人民友好程度，所在城市的消费水平，学校的毕业难度，自己能否适应德国，以及学历回国认可度等等因素。 德国人一向严谨，APS只不过是申请的第一道关卡，相比于其他欧洲国家的话还是多了很多麻烦的步骤，比如有的学校还要申请VPD。所以大家在决定申请德国高校的时候一定要做好比别人迟几个月才能拿offer的准备，德语不好的同学更要准备好在当地生活可能出现的不方便，与人交流的不方便情况。在大城市慕尼黑更是有房租价高而且不好租到，物价很贵的方方面面。 最后希望各位留学党都能做出适合自己的选择。祝各位一切都好~ 撒花","link":"/2019/03/27/APS经验/"}],"tags":[{"name":"deep learning","slug":"deep-learning","link":"/tags/deep-learning/"},{"name":"博客搭建","slug":"博客搭建","link":"/tags/博客搭建/"},{"name":"数据标注","slug":"数据标注","link":"/tags/数据标注/"},{"name":"年度总结","slug":"年度总结","link":"/tags/年度总结/"},{"name":"德国留学","slug":"德国留学","link":"/tags/德国留学/"}],"categories":[{"name":"课程笔记","slug":"课程笔记","link":"/categories/课程笔记/"},{"name":"技术杂谈","slug":"技术杂谈","link":"/categories/技术杂谈/"},{"name":"生活随笔","slug":"生活随笔","link":"/categories/生活随笔/"}]}